{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated MultiINPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0570122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import utils, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import time\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "## Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "director_node_fqdn = 'ai2'\n",
    "director_port=50051\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port, \n",
    "    tls=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0dbdbd",
   "metadata": {},
   "source": [
    "## Describing FL experimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3081a6",
   "metadata": {},
   "source": [
    "## Load MedMNIST INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecd1b16",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0377d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "experiment_name= \"FL_MultiInput\"\n",
    "epochs = 200\n",
    "\n",
    "myseed = 11\n",
    "torch.manual_seed(myseed)\n",
    "np.random.seed(myseed)\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(myseed)\n",
    "\n",
    "num_classes=1\n",
    "\n",
    "\n",
    "all_columns = ['AGE','PTGENDER','ADAS11', 'MMSE', 'FAQ', \\\n",
    "               'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', \\\n",
    "               'CDRSB', 'APOE4']\n",
    "\n",
    "required_columns = ['AGE','PTGENDER','APOE4']\n",
    "\n",
    "if len(required_columns) == len(all_columns):\n",
    "    experiment_name = 'img_full10'\n",
    "else:\n",
    "    experiment_name = experiment_name + \"_\" + str(myseed) + '_img_' + ('_'.join(required_columns)).lower()\n",
    "print(f\"{experiment_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0979470",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    \"\"\"Data extraction\"\"\"\n",
    "\n",
    "    def __init__(self, input_dataframe, transform=None, required_columns=required_columns):\n",
    "        \"\"\"Initialize Dataset.\"\"\"\n",
    "        self.input_df = input_dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length of dataset.\"\"\"\n",
    "        return len(self.input_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = index.tolist()\n",
    "\n",
    "        line = self.input_df[idx]#[idx, 0:]\n",
    "        \n",
    "        # Get Label\n",
    "        y = line['labels']\n",
    "        \n",
    "        # Get tabular\n",
    "        tabular = line[required_columns]\n",
    "        tabular = torch.DoubleTensor(tabular)\n",
    "                   \n",
    "        # Get image\n",
    "        img_path= os.path.join(line['IMG_PATH'])\n",
    "        image = nib.load(img_path)\n",
    "        image = image.get_fdata() \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.unsqueeze(dim=0)\n",
    "        \n",
    "        return image, tabular, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiINPUTFedDataset(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "        \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "\n",
    "        self.train_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('train'),\n",
    "            transform=None, required_columns = required_columns\n",
    "        )       \n",
    "        \n",
    "        self.valid_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('val'),\n",
    "            transform=None, required_columns = required_columns\n",
    "        )\n",
    "        \n",
    "       \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_set, num_workers=1, batch_size=self.kwargs['train_bs'], shuffle=True)\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(self.valid_set, num_workers=1, batch_size=self.kwargs['valid_bs'])\n",
    "\n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfb459",
   "metadata": {},
   "source": [
    "### Create Mnist federated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af5c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = MultiINPUTFedDataset(train_bs=8, valid_bs=8, test_bs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005760c",
   "metadata": {},
   "source": [
    "## Describe the model and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e343b3",
   "metadata": {},
   "source": [
    "## Multi_input net: 3D ResNet + MPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inplanes():\n",
    "    return [64, 128, 256, 512]\n",
    "\n",
    "\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "def conv1x1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv1x1x1(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = conv3x3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, block_inplanes, \\\n",
    "                 n_input_channels=3, conv1_t_size=7, \\\n",
    "                 conv1_t_stride=1, no_max_pool=False, \\\n",
    "                 shortcut_type='B', widen_factor=1.0, \\\n",
    "                 n_classes=400, img_contribution=10, \\\n",
    "                 tabular_val=10, tabular_contribution=10):\n",
    "        super().__init__()\n",
    "\n",
    "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
    "\n",
    "        self.in_planes = block_inplanes[0]\n",
    "        self.no_max_pool = no_max_pool\n",
    "\n",
    "        self.conv1 = nn.Conv3d(n_input_channels,\n",
    "                               self.in_planes,\n",
    "                               kernel_size=(conv1_t_size, 7, 7),\n",
    "                               stride=(conv1_t_stride, 2, 2),\n",
    "                               padding=(conv1_t_size // 2, 3, 3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n",
    "                                       shortcut_type)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       block_inplanes[1],\n",
    "                                       layers[1],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       block_inplanes[2],\n",
    "                                       layers[2],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       block_inplanes[3],\n",
    "                                       layers[3],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, img_contribution)\n",
    "        \n",
    "        #qui ho cambiato da num_classes a 10, per far cat con testo\n",
    "        #TESTO\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln1 = nn.Linear(tabular_val, 50) #23 sono le colonne in input\n",
    "        self.ln2 = nn.Linear(50, 50)\n",
    "        self.ln3 = nn.Linear(50, tabular_contribution)\n",
    "        self.ln4 = nn.Linear(tabular_contribution+img_contribution, n_classes) #20 perchÃ¨ 10 derivano da img e 10 da tab\n",
    "        \n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _downsample_basic_block(self, x, planes, stride):\n",
    "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n",
    "                                out.size(3), out.size(4))\n",
    "        if isinstance(out.data, torch.FloatTensor):\n",
    "            zero_pads = zero_pads\n",
    "\n",
    "        out = torch.cat([out.data, zero_pads], dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            if shortcut_type == 'A':\n",
    "                downsample = partial(self._downsample_basic_block,\n",
    "                                     planes=planes * block.expansion,\n",
    "                                     stride=stride)\n",
    "            else:\n",
    "                downsample = nn.Sequential(\n",
    "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
    "                    nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(in_planes=self.in_planes,\n",
    "                  planes=planes,\n",
    "                  stride=stride,\n",
    "                  downsample=downsample))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, tab):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if not self.no_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        tab = self.ln1(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln2(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln3(tab)\n",
    "        tab = self.relu(tab)\n",
    "        \n",
    "        x = torch.cat((x, tab), dim=1)\n",
    "        x= self.relu(x)\n",
    "        \n",
    "        x = self.ln4(x)        \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def ResNet18(in_channels, num_classes):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "def generate_model(model_depth, **kwargs):\n",
    "    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n",
    "\n",
    "    if model_depth == 10:\n",
    "        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 152:\n",
    "        model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 200:\n",
    "        model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = generate_model(18, n_input_channels=1, widen_factor=1.0, \\\n",
    "                       n_classes=1, img_contribution=10, \\\n",
    "                       tabular_val=len(required_columns), tabular_contribution=10)\n",
    "model = model.double()\n",
    "print(model)\n",
    "\n",
    "\n",
    "print('Total Parameters:',\n",
    "      sum([torch.numel(p) for p in model.parameters()]))\n",
    "print('Trainable Parameters:',\n",
    "      sum([torch.numel(p) for p in model.parameters() if p.requires_grad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Params\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "## Define a loss \n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c78ee",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59831bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c165b",
   "metadata": {},
   "source": [
    "## Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "train_custom_params={'criterion':criterion}\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**train_custom_params)\n",
    "@TI.register_fl_task(model='model', data_loader='train_loader',\n",
    "                     device='device', optimizer='optimizer')\n",
    "def train(model, train_loader, device, optimizer, criterion):\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    \n",
    "    total_loss, total_acc, total_samples = [],0,0\n",
    "\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    for img, tabular, labels in train_loader:\n",
    "        img, tabular, labels = torch.tensor(img).to(device), torch.tensor(tabular).to(device), torch.tensor(labels).to(device, dtype=torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute output\n",
    "        pred = model(img, tabular)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(pred.float(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update loss\n",
    "        total_loss.append(loss.item())\n",
    "        pred_labels = (pred >= 0).float() # Binarize predictions to 0 and 1\n",
    "        batch_accuracy = (pred_labels == labels).sum().item()/img.size(0)\n",
    "        # Update accuracy\n",
    "        total_acc += batch_accuracy\n",
    "\n",
    "    return {'train_loss': np.mean(total_loss), \n",
    "            'train_acc':  total_acc/len(train_loader)}\n",
    "\n",
    "\n",
    "val_custom_params={'criterion':criterion}\n",
    "\n",
    "@TI.add_kwargs(**val_custom_params)\n",
    "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')\n",
    "def validate(model, val_loader, device, criterion):\n",
    "\n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "    total_loss, total_acc, total_samples = [],0,0\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for img, tabular, labels in val_loader:\n",
    "            img, tabular, labels = torch.tensor(img).to(device), torch.tensor(tabular).to(device), torch.tensor(labels).to(device, dtype=torch.int64)\n",
    "\n",
    "            # Compute output\n",
    "            pred = model(img, tabular)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            labels = labels.float()\n",
    "            loss = criterion(pred.float(), labels)  \n",
    "            \n",
    "            # update loss\n",
    "            total_loss.append(loss.item())\n",
    "            pred_labels = (pred >= 0).float()\n",
    "            \n",
    "             # Binarize predictions to 0 and 1\n",
    "            batch_accuracy = (pred_labels == labels).sum().item()/img.size(0)\n",
    "            # Update accuracy\n",
    "            total_acc += batch_accuracy\n",
    "\n",
    "        return {'val_loss': np.mean(total_loss),\n",
    "                'val_acc': total_acc/len(val_loader)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b44de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=epochs,\n",
    "                    opt_treatment='RESET',\n",
    "                    device_assignment_policy='CUDA_PREFERRED',\n",
    "                    pip_install_options=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa7cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
    "fl_experiment.restore_experiment_state(MI)\n",
    "fl_experiment.stream_metrics(tensorboard_logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef600100",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd975242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLexperiment.get_best_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adni_fl",
   "language": "python",
   "name": "adni_fl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
