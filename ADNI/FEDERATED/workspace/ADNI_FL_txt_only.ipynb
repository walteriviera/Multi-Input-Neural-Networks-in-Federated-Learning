{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fdd9ed",
   "metadata": {},
   "source": [
    "# Federated TxTOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0570122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if not already installed\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import utils, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import time\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f9c98",
   "metadata": {},
   "source": [
    "## Connect to the Federation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d657e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a federation\n",
    "from openfl.interface.interactive_api.federation import Federation\n",
    "\n",
    "# please use the same identificator that was used in signed certificate\n",
    "client_id = 'api'\n",
    "director_node_fqdn = 'ai2'\n",
    "director_port=50051\n",
    "\n",
    "# 2) Run with TLS disabled (trusted environment)\n",
    "# Federation can also determine local fqdn automatically\n",
    "federation = Federation(\n",
    "    client_id=client_id,\n",
    "    director_node_fqdn=director_node_fqdn,\n",
    "    director_port=director_port, \n",
    "    tls=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dcfab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_registry = federation.get_shard_registry()\n",
    "shard_registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6c237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, request a dummy_shard_desc that holds information about the federated dataset \n",
    "dummy_shard_desc = federation.get_dummy_shard_descriptor(size=10)\n",
    "dummy_shard_dataset = dummy_shard_desc.get_dataset('train')\n",
    "sample, target = dummy_shard_dataset[0]\n",
    "f\"Sample shape: {sample.shape}, target shape: {target.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0dbdbd",
   "metadata": {},
   "source": [
    "## Describing FL experimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc88700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openfl.interface.interactive_api.experiment import TaskInterface, DataInterface, ModelInterface, FLExperiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3081a6",
   "metadata": {},
   "source": [
    "## Load MedMNIST INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecd1b16",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0377d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "experiment_name= \"FL_txt_only\"\n",
    "epochs = 200\n",
    "\n",
    "myseed = 14\n",
    "torch.manual_seed(myseed)\n",
    "np.random.seed(myseed)\n",
    "generator = torch.Generator()\n",
    "generator.manual_seed(myseed)\n",
    "\n",
    "num_classes=1\n",
    "\n",
    "all_columns = ['AGE','PTGENDER','ADAS11', 'MMSE', 'FAQ', \\\n",
    "               'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', \\\n",
    "               'CDRSB', 'APOE4']\n",
    "\n",
    "required_columns = ['AGE','PTGENDER','APOE4']\n",
    "\n",
    "if len(required_columns) == len(all_columns):\n",
    "    experiment_name = 'img_full10'\n",
    "else:\n",
    "    experiment_name = experiment_name + \"_\" + str(myseed)+ \"_\" +('_'.join(required_columns)).lower()\n",
    "print(f\"{experiment_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0979470",
   "metadata": {},
   "source": [
    "### Register dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformedDataset(Dataset):\n",
    "    \"\"\"Data extraction\"\"\"\n",
    "\n",
    "    def __init__(self, input_dataframe, transform=None, required_columns=required_columns):\n",
    "        \"\"\"Initialize Dataset.\"\"\"\n",
    "        self.input_df = input_dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Length of dataset.\"\"\"\n",
    "        return len(self.input_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = index.tolist()\n",
    "\n",
    "        line = self.input_df[idx]\n",
    "        \n",
    "        # Get Label\n",
    "        y = line['labels']\n",
    "        \n",
    "        # Get tabular\n",
    "        tabular = line[required_columns]\n",
    "        tabular = torch.DoubleTensor(tabular)\n",
    "\n",
    "        return tabular, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiINPUTFedDataset(DataInterface):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    @property\n",
    "    def shard_descriptor(self):\n",
    "        return self._shard_descriptor\n",
    "        \n",
    "    @shard_descriptor.setter\n",
    "    def shard_descriptor(self, shard_descriptor):\n",
    "        \"\"\"\n",
    "        Describe per-collaborator procedures or sharding.\n",
    "\n",
    "        This method will be called during a collaborator initialization.\n",
    "        Local shard_descriptor  will be set by Envoy.\n",
    "        \"\"\"\n",
    "        self._shard_descriptor = shard_descriptor\n",
    "\n",
    "        self.train_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('train'),\n",
    "            required_columns=required_columns,\n",
    "            transform=None\n",
    "        )       \n",
    "        \n",
    "        self.valid_set = TransformedDataset(\n",
    "            self._shard_descriptor.get_dataset('val'),\n",
    "            required_columns=required_columns,\n",
    "            transform=None\n",
    "        )\n",
    "       \n",
    "    def get_train_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks with optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(\n",
    "            self.train_set, num_workers=1, batch_size=self.kwargs['train_bs'], shuffle=True)\n",
    "\n",
    "    def get_valid_loader(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Output of this method will be provided to tasks without optimizer in contract\n",
    "        \"\"\"\n",
    "        return DataLoader(self.valid_set, num_workers=1, batch_size=self.kwargs['valid_bs'])\n",
    "    \n",
    "    def get_train_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.train_set)\n",
    "\n",
    "    def get_valid_data_size(self):\n",
    "        \"\"\"\n",
    "        Information for aggregation\n",
    "        \"\"\"\n",
    "        return len(self.valid_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dfb459",
   "metadata": {},
   "source": [
    "### Create Mnist federated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952462eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_fed_dataset = MultiINPUTFedDataset(train_bs=8, valid_bs=8, test_bs=8)\n",
    "from walter_sd_test import MultiINPUTShardDescriptor as misd\n",
    "adni_num=1\n",
    "TEST_fed_dataset.shard_descriptor = misd(adni_num=adni_num,\n",
    "                                    data_dir= f'/home/user1/fast_storage/a{adni_num}',\n",
    "                                    img_dir= f'ADNI{adni_num}_ALL_T1',\n",
    "                                    csv_path= '/home/user1/fast_storage/ADNI_csv')\n",
    "\n",
    "for i, (sample, target) in enumerate(TEST_fed_dataset.get_train_loader()):\n",
    "    if not i == 1:\n",
    "        print(sample, target)\n",
    "        print(sample.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35781fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "fed_dataset = MultiINPUTFedDataset(train_bs=8, valid_bs=8, test_bs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f005760c",
   "metadata": {},
   "source": [
    "## Describe the model and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e343b3",
   "metadata": {},
   "source": [
    "## IMG-Only Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f74d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class TextNN(nn.Module):\n",
    "\n",
    "    #Constructor\n",
    "    def __init__(self, num_variables):\n",
    "    # Call parent contructor\n",
    "        super().__init__()\n",
    "        #torch.manual_seed(myseed)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.ln1 = nn.Linear(num_variables, 50) #num_variables sono le colonne in input\n",
    "        self.ln2 = nn.Linear(50, 50)\n",
    "        self.ln3 = nn.Linear(50, 10)\n",
    "        self.ln4 = nn.Linear(10, 1)\n",
    "    \n",
    "    def forward(self, tab):\n",
    "        tab = self.ln1(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln2(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln3(tab)\n",
    "        tab = self.relu(tab)\n",
    "        tab = self.ln4(tab)\n",
    "\n",
    "        return tab\n",
    "\n",
    "model = TextNN(len(required_columns)) # required_columns - label column\n",
    "model = model.double()\n",
    "print(model)\n",
    "\n",
    "print('Total Parameters:',\n",
    "      sum([torch.numel(p) for p in model.parameters()]))\n",
    "print('Trainable Parameters:',\n",
    "      sum([torch.numel(p) for p in model.parameters() if p.requires_grad]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Params\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "## Define a loss \n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1c78ee",
   "metadata": {},
   "source": [
    "### Register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59831bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "framework_adapter = 'openfl.plugins.frameworks_adapters.pytorch_adapter.FrameworkAdapterPlugin'\n",
    "MI = ModelInterface(model=model, optimizer=optimizer, framework_plugin=framework_adapter)\n",
    "\n",
    "# Save the initial model state\n",
    "initial_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c165b",
   "metadata": {},
   "source": [
    "## Define and register FL tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff463bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TI = TaskInterface()\n",
    "\n",
    "train_custom_params={'criterion':criterion}\n",
    "\n",
    "# Task interface currently supports only standalone functions.\n",
    "@TI.add_kwargs(**train_custom_params)\n",
    "@TI.register_fl_task(model='model', data_loader='train_loader',\n",
    "                     device='device', optimizer='optimizer')\n",
    "def train(model, train_loader, device, optimizer, criterion):\n",
    "    \n",
    "    train_loader = tqdm.tqdm(train_loader, desc=\"train\")\n",
    "    \n",
    "    total_loss, total_acc, total_samples = [],0,0\n",
    "    #scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr = 0.01, epochs=epochs, steps_per_epoch=len(train_loader))    \n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    for tab, labels in train_loader:\n",
    "        tab, labels = torch.tensor(tab).to(device), torch.tensor(labels).to(device, dtype=torch.int64)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute output\n",
    "        pred = model(tab)\n",
    "        labels = labels.unsqueeze(1)\n",
    "        labels = labels.float()\n",
    "        loss = criterion(pred.float(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # update loss\n",
    "        total_loss.append(loss.item())\n",
    "        pred_labels = (pred >= 0).float() # Binarize predictions to 0 and 1\n",
    "        batch_accuracy = (pred_labels == labels).sum().item()/tab.size(0)\n",
    "        # Update accuracy\n",
    "        total_acc += batch_accuracy\n",
    "\n",
    "    return {'train_loss': np.mean(total_loss), \n",
    "            'train_acc': total_acc/len(train_loader),}\n",
    "\n",
    "\n",
    "val_custom_params={'criterion':criterion}\n",
    "\n",
    "@TI.add_kwargs(**val_custom_params)\n",
    "@TI.register_fl_task(model='model', data_loader='val_loader', device='device')\n",
    "def validate(model, val_loader, device, criterion):\n",
    "\n",
    "    val_loader = tqdm.tqdm(val_loader, desc=\"validate\")\n",
    "    total_loss, total_acc, total_samples = [],0,0\n",
    "    \n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for tab, labels in val_loader:           \n",
    "            tab, labels = torch.tensor(tab).to(device), torch.tensor(labels).to(device, dtype=torch.int64)\n",
    "\n",
    "            # Compute output\n",
    "            pred = model(tab)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            labels = labels.float()\n",
    "            loss = criterion(pred.float(), labels)  \n",
    "            \n",
    "            # update loss\n",
    "            total_loss.append(loss.item())\n",
    "            pred_labels = (pred >= 0).float()\n",
    "            \n",
    "             # Binarize predictions to 0 and 1\n",
    "            batch_accuracy = (pred_labels == labels).sum().item()/tab.size(0)\n",
    "            # Update accuracy\n",
    "            total_acc += batch_accuracy\n",
    "\n",
    "        return {'val_loss': np.mean(total_loss),\n",
    "                'val_acc': total_acc/len(val_loader),}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ebf2d",
   "metadata": {},
   "source": [
    "## Time to start a federated learning experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b7896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an experimnet in federation\n",
    "fl_experiment = FLExperiment(federation=federation, experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b44de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following command zips the workspace and python requirements to be transfered to collaborator nodes\n",
    "fl_experiment.start(model_provider=MI, \n",
    "                    task_keeper=TI,\n",
    "                    data_loader=fed_dataset,\n",
    "                    rounds_to_train=epochs,\n",
    "                    opt_treatment='RESET',\n",
    "                    device_assignment_policy='CUDA_PREFERRED',\n",
    "                    pip_install_options=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa7cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If user want to stop IPython session, then reconnect and check how experiment is going\n",
    "fl_experiment.restore_experiment_state(MI)\n",
    "fl_experiment.stream_metrics(tensorboard_logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef600100",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd975242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FLexperiment.get_best_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adni_fl",
   "language": "python",
   "name": "adni_fl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
